{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vS_0d48Ojx0q",
        "outputId": "708083b6-34f2-4d40-ec70-9918c5f20b2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/My Drive/EVA_MiLab_Hackathon\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd /content/gdrive/My Drive/EVA_MiLab_Hackathon\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFsQ0KVWlGZb",
        "outputId": "a90898ad-70e6-4883-8ed9-0e40e8d90c10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting swig\n",
            "  Downloading swig-4.3.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (3.5 kB)\n",
            "Downloading swig-4.3.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: swig\n",
            "Successfully installed swig-4.3.0\n",
            "Requirement already satisfied: gymnasium==1.0.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]==1.0.0) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium==1.0.0->gymnasium[box2d]==1.0.0) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium==1.0.0->gymnasium[box2d]==1.0.0) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium==1.0.0->gymnasium[box2d]==1.0.0) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium==1.0.0->gymnasium[box2d]==1.0.0) (0.0.4)\n",
            "Collecting box2d-py==2.3.5 (from gymnasium[box2d]==1.0.0)\n",
            "  Downloading box2d-py-2.3.5.tar.gz (374 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.4/374.4 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pygame>=2.1.3 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]==1.0.0) (2.6.1)\n",
            "Requirement already satisfied: swig==4.* in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]==1.0.0) (4.3.0)\n",
            "Building wheels for collected packages: box2d-py\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for box2d-py: filename=box2d_py-2.3.5-cp311-cp311-linux_x86_64.whl size=2379448 sha256=ed8df7ac8d5ae35021ca5147b94815c417e8489f0a1b597ed0e24dd687885530\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/f1/0c/d56f4a2bdd12bae0a0693ec33f2f0daadb5eb9753c78fa5308\n",
            "Successfully built box2d-py\n",
            "Installing collected packages: box2d-py\n",
            "Successfully installed box2d-py-2.3.5\n"
          ]
        }
      ],
      "source": [
        "!pip install swig\n",
        "!pip install \"gymnasium[box2d]==1.0.0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1iP0c4K19dth"
      },
      "outputs": [],
      "source": [
        "from itertools import count\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from time import gmtime, strftime\n",
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import torch\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "from utils.env_wrapper import Env\n",
        "from agents.cnn_dqn import CNN_DQN_Agent\n",
        "\n",
        "\n",
        "def plot_durations(episode_durations, show_result=False, save_path=None):\n",
        "    plt.figure(1)\n",
        "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
        "    if show_result:\n",
        "        plt.title('Result')\n",
        "    else:\n",
        "        plt.clf()\n",
        "        plt.title('Training...')\n",
        "    plt.xlabel('Episode')\n",
        "    plt.ylabel('Duration')\n",
        "    plt.plot(durations_t.numpy())\n",
        "    # Take 100 episode averages and plot them too\n",
        "    if len(durations_t) >= 100:\n",
        "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
        "        means = torch.cat((torch.zeros(99), means))\n",
        "        plt.plot(means.numpy())\n",
        "\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "    if is_ipython:\n",
        "        if not show_result:\n",
        "            display.display(plt.gcf())\n",
        "            display.clear_output(wait=True)\n",
        "        else:\n",
        "            display.display(plt.gcf())\n",
        "\n",
        "    # Save the plot if a save path is provided\n",
        "    if save_path:\n",
        "        plt.savefig(save_path)\n",
        "        print(f\"Plot saved at {save_path}\")\n",
        "\n",
        "\n",
        "def train_agent(episodes, run_name, env_hyperparameters, hyperparameters):\n",
        "    env = Env(\"CarRacing-v3\",\n",
        "              **env_hyperparameters)\n",
        "\n",
        "    agent = CNN_DQN_Agent(\n",
        "        input_shape=env.env.observation_space.shape,\n",
        "        DISCRETE_ACTIONS = env.DISCRETE_ACTIONS,\n",
        "        run_name = run_name,\n",
        "        img_stack = env_hyperparameters['img_stack'],\n",
        "        **hyperparameters\n",
        "        )\n",
        "    # agent.load_checkpoint()\n",
        "\n",
        "\n",
        "    for episode in range(episodes):\n",
        "        state, info = env.reset()\n",
        "        \n",
        "        total_reward = 0\n",
        "        done = False\n",
        "\n",
        "        for t in count():\n",
        "            action = agent.select_action(state)\n",
        "            \n",
        "            observation, reward, terminated, truncated, info = env.step(\n",
        "                agent.get_action_from_action_index(action.item()).cpu().numpy()\n",
        "                )\n",
        "            reward = torch.tensor([reward], device=agent.device)\n",
        "            done = terminated or truncated\n",
        "\n",
        "            if terminated:\n",
        "                next_state = None\n",
        "            else:\n",
        "                next_state = torch.tensor(observation, dtype=torch.float32, device=agent.device).unsqueeze(0)\n",
        "            \n",
        "            agent.memory.push(\n",
        "                  state.to(agent.device), \n",
        "                  action.to(agent.device), \n",
        "                  next_state.to(agent.device) if next_state is not None else None, \n",
        "                  reward.to(agent.device))\n",
        "            agent.train_step()\n",
        "            state = next_state\n",
        "            total_reward += reward\n",
        "\n",
        "            if done:\n",
        "              agent.episode_durations.append(t + 1)\n",
        "              # plot_durations(agent.episode_durations)\n",
        "\n",
        "              # Save plot at the end of training\n",
        "              # if episode == episodes - 1:  # Last episode\n",
        "                  # plot_durations(agent.episode_durations, show_result=True, save_path=f\"plots/{run_name}_training_plot.png\")\n",
        "              break\n",
        "\n",
        "        agent.log_reward(episode, total_reward)\n",
        "\n",
        "        if episode % 50 == 0 and episode > 0:\n",
        "            agent.save_checkpoint(episode)\n",
        "\n",
        "\n",
        "\n",
        "        print(f\"Episode {episode}: Total Reward: {total_reward.cpu().item()}. Steps done: {agent.steps}\")\n",
        "\n",
        "    env.close()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "PxvNfRQK1r-f",
        "outputId": "3037b93c-1404-4709-88e2-65b941f48ffe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 499: Total Reward: 14.942222595214844\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "is_ipython = 'inline' in matplotlib.get_backend()\n",
        "if is_ipython:\n",
        "    from IPython import display\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device {device}\")\n",
        "\n",
        "env_hyperparameters = {\n",
        "    \"random_seed\": 1,\n",
        "    \"img_stack\": 4, # Number of frames per state\n",
        "    \"action_repeat\": 8 # How many times to repeach each action per state\n",
        "}\n",
        "\n",
        "hyperparameters = {\n",
        "    \"batch_size\": 128,  # More stable training\n",
        "    \"gamma\": 0.99,  # Focus more on long-term rewards\n",
        "    \"epsilon_start\": 0.9,\n",
        "    \"epsilon_end\": 0.05,\n",
        "    \"tau\": 0.005,  # Faster soft updates\n",
        "    \"epsilon_decay_steps\": 500,  # Balance exploration & exploitation\n",
        "    \"learning_rate\": 1e-4,  # Keep same\n",
        "    \"replay_buffer_size\": 10000,  # Store more experience\n",
        "}\n",
        "\n",
        "\n",
        "RUN_NAME = f\"CNN_DQN_{strftime('%Y%m%d%H%M%S', gmtime())}\"\n",
        "train_agent(\n",
        "    episodes = 2000, \n",
        "    run_name = RUN_NAME,\n",
        "    env_hyperparameters = env_hyperparameters,\n",
        "    hyperparameters = hyperparameters\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sxHqel4N4SZm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FelW0JGH1g3E"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
