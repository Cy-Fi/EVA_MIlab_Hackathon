{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd /content/gdrive/My Drive/EVA_MiLab_Hackathon\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vS_0d48Ojx0q",
        "outputId": "708083b6-34f2-4d40-ec70-9918c5f20b2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/My Drive/EVA_MiLab_Hackathon\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install swig\n",
        "!pip install \"gymnasium[box2d]==1.0.0\""
      ],
      "metadata": {
        "id": "tFsQ0KVWlGZb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a90898ad-70e6-4883-8ed9-0e40e8d90c10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting swig\n",
            "  Downloading swig-4.3.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (3.5 kB)\n",
            "Downloading swig-4.3.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: swig\n",
            "Successfully installed swig-4.3.0\n",
            "Requirement already satisfied: gymnasium==1.0.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]==1.0.0) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium==1.0.0->gymnasium[box2d]==1.0.0) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium==1.0.0->gymnasium[box2d]==1.0.0) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium==1.0.0->gymnasium[box2d]==1.0.0) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium==1.0.0->gymnasium[box2d]==1.0.0) (0.0.4)\n",
            "Collecting box2d-py==2.3.5 (from gymnasium[box2d]==1.0.0)\n",
            "  Downloading box2d-py-2.3.5.tar.gz (374 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.4/374.4 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pygame>=2.1.3 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]==1.0.0) (2.6.1)\n",
            "Requirement already satisfied: swig==4.* in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]==1.0.0) (4.3.0)\n",
            "Building wheels for collected packages: box2d-py\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for box2d-py: filename=box2d_py-2.3.5-cp311-cp311-linux_x86_64.whl size=2379448 sha256=ed8df7ac8d5ae35021ca5147b94815c417e8489f0a1b597ed0e24dd687885530\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/f1/0c/d56f4a2bdd12bae0a0693ec33f2f0daadb5eb9753c78fa5308\n",
            "Successfully built box2d-py\n",
            "Installing collected packages: box2d-py\n",
            "Successfully installed box2d-py-2.3.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import count\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from time import gmtime, strftime\n",
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import torch\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "from agents.cnn_dqn import CNN_DQN_Agent\n",
        "\n",
        "\n",
        "def plot_durations(episode_durations, show_result=False, save_path=None):\n",
        "    plt.figure(1)\n",
        "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
        "    if show_result:\n",
        "        plt.title('Result')\n",
        "    else:\n",
        "        plt.clf()\n",
        "        plt.title('Training...')\n",
        "    plt.xlabel('Episode')\n",
        "    plt.ylabel('Duration')\n",
        "    plt.plot(durations_t.numpy())\n",
        "    # Take 100 episode averages and plot them too\n",
        "    if len(durations_t) >= 100:\n",
        "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
        "        means = torch.cat((torch.zeros(99), means))\n",
        "        plt.plot(means.numpy())\n",
        "\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "    if is_ipython:\n",
        "        if not show_result:\n",
        "            display.display(plt.gcf())\n",
        "            display.clear_output(wait=True)\n",
        "        else:\n",
        "            display.display(plt.gcf())\n",
        "\n",
        "    # Save the plot if a save path is provided\n",
        "    if save_path:\n",
        "        plt.savefig(save_path)\n",
        "        print(f\"Plot saved at {save_path}\")\n",
        "\n",
        "\n",
        "def train_agent(episodes, run_name):\n",
        "    env = gym.make(\"CarRacing-v3\", render_mode=\"rgb_array\", lap_complete_percent=0.95, domain_randomize=False, continuous=True)\n",
        "\n",
        "    agent = CNN_DQN_Agent(\n",
        "        input_shape=env.observation_space.shape,\n",
        "        action_space=env.action_space,\n",
        "        run_name = RUN_NAME,\n",
        "        **hyperparameters\n",
        "        )\n",
        "    # agent.load_checkpoint()\n",
        "\n",
        "\n",
        "    for episode in range(episodes):\n",
        "        state, info = env.reset()\n",
        "        state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
        "        total_reward = 0\n",
        "        done = False\n",
        "\n",
        "        for t in count():\n",
        "            action = agent.select_action(state)\n",
        "\n",
        "            observation, reward, terminated, truncated, info = env.step(action.cpu().numpy())\n",
        "            reward = torch.tensor([reward], device=device)\n",
        "            done = terminated or truncated\n",
        "\n",
        "            if terminated:\n",
        "                next_state = None\n",
        "            else:\n",
        "                next_state = torch.tensor(observation, dtype=torch.float32, device=device).unsqueeze(0)\n",
        "\n",
        "            agent.memory.push(state.to(agent.device), action.to(agent.device), next_state.to(agent.device), reward.to(agent.device))\n",
        "            agent.train_step()\n",
        "            state = next_state\n",
        "            total_reward += reward\n",
        "\n",
        "            if done:\n",
        "              agent.episode_durations.append(t + 1)\n",
        "              plot_durations(agent.episode_durations)\n",
        "\n",
        "              # Save plot at the end of training\n",
        "              if episode == episodes - 1:  # Last episode\n",
        "                  plot_durations(agent.episode_durations, show_result=True, save_path=f\"plots/{run_name}_training_plot.png\")\n",
        "              break\n",
        "\n",
        "        agent.log_reward(episode, total_reward)\n",
        "\n",
        "        if episode % 50 == 0 and episode > 0:\n",
        "            agent.save_checkpoint(episode)\n",
        "\n",
        "\n",
        "\n",
        "        print(f\"Episode {episode}: Total Reward: {total_reward.cpu().item()}\")\n",
        "\n",
        "    env.close()\n",
        "\n"
      ],
      "metadata": {
        "id": "1iP0c4K19dth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "is_ipython = 'inline' in matplotlib.get_backend()\n",
        "if is_ipython:\n",
        "    from IPython import display\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device {device}\")\n",
        "\n",
        "hyperparameters = {\n",
        "    \"batch_size\": 128,  # More stable training\n",
        "    \"gamma\": 0.99,  # Focus more on long-term rewards\n",
        "    \"epsilon_start\": 1.0,\n",
        "    \"epsilon_end\": 0.1,\n",
        "    \"tau\": 0.01,  # Faster soft updates\n",
        "    \"epsilon_decay_steps\": 25000,  # Balance exploration & exploitation\n",
        "    \"learning_rate\": 0.0003,  # Keep same\n",
        "    \"replay_buffer_size\": 50000,  # Store more experience\n",
        "    \"steps_per_target_net_update\": 1000  # Update target net less frequently\n",
        "}\n",
        "\n",
        "\n",
        "RUN_NAME = f\"CNN_DQN_{strftime('%Y%m%d%H%M%S', gmtime())}\"\n",
        "train_agent(episodes = 500, run_name = RUN_NAME)"
      ],
      "metadata": {
        "id": "PxvNfRQK1r-f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "3037b93c-1404-4709-88e2-65b941f48ffe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 499: Total Reward: 14.942222595214844\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sxHqel4N4SZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FelW0JGH1g3E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}