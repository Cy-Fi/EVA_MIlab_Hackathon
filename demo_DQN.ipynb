{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7Y9LFqkWzlF",
        "outputId": "f4f33c40-0d82-4da6-a540-151379d6dbfe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/My Drive/EVA_MiLab_Hackathon\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd /content/gdrive/My Drive/EVA_MiLab_Hackathon\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCCRPfp1W60o",
        "outputId": "3950553e-e747-4893-d338-43f7a05134a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting swig\n",
            "  Downloading swig-4.3.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (3.5 kB)\n",
            "Downloading swig-4.3.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: swig\n",
            "Successfully installed swig-4.3.0\n",
            "Requirement already satisfied: gymnasium==1.0.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]==1.0.0) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium==1.0.0->gymnasium[box2d]==1.0.0) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium==1.0.0->gymnasium[box2d]==1.0.0) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium==1.0.0->gymnasium[box2d]==1.0.0) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium==1.0.0->gymnasium[box2d]==1.0.0) (0.0.4)\n",
            "Collecting box2d-py==2.3.5 (from gymnasium[box2d]==1.0.0)\n",
            "  Downloading box2d-py-2.3.5.tar.gz (374 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.4/374.4 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pygame>=2.1.3 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]==1.0.0) (2.6.1)\n",
            "Requirement already satisfied: swig==4.* in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]==1.0.0) (4.3.0)\n",
            "Building wheels for collected packages: box2d-py\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for box2d-py: filename=box2d_py-2.3.5-cp311-cp311-linux_x86_64.whl size=2379442 sha256=317979f6e8128925dc64b86f3ab36bf9b6a2d17d66437032c82a08913a4f48d5\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/f1/0c/d56f4a2bdd12bae0a0693ec33f2f0daadb5eb9753c78fa5308\n",
            "Successfully built box2d-py\n",
            "Installing collected packages: box2d-py\n",
            "Successfully installed box2d-py-2.3.5\n"
          ]
        }
      ],
      "source": [
        "!pip install swig\n",
        "!pip install \"gymnasium[box2d]==1.0.0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X466zWh9qLbi",
        "outputId": "6ee3f238-ab1c-4d0b-e1c5-a94758b52f7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checkpoint loaded from checkpoints/cnn_dqn/CNN_DQN_20250212080610_episode_500.pth on cpu\n",
            "Episode 1: Total Reward: -17.918855218855057\n",
            "Episode 2: Total Reward: -18.033333333333278\n",
            "Episode 3: Total Reward: -17.976433121019056\n",
            "Video saved as demo/CNN_DQN_20250212080610_episode_500_car_demo.mp4\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "from agents.cnn_dqn import CNN_DQN_Agent\n",
        "from utils.env_wrapper import Env\n",
        "from google.colab.patches import cv2_imshow\n",
        "from google.colab import files\n",
        "\n",
        "# Function to run the trained agent and record video\n",
        "def evaluate_agent(checkpoint_file, episodes=1):\n",
        "    filename = checkpoint_file[:-4]\n",
        "    output_video = f\"demo/{filename}_car_demo.mp4\"\n",
        "\n",
        "\n",
        "    # Environment hyperparameters\n",
        "    env_hyperparameters = {\n",
        "        \"random_seed\": 3,\n",
        "        \"img_stack\": 4,  # Number of frames per state\n",
        "        \"action_repeat\": 8\n",
        "    }\n",
        "\n",
        "    # Initialize environment\n",
        "    env = Env(\"CarRacing-v3\", **env_hyperparameters)\n",
        "\n",
        "    # Agent hyperparameters (same as training settings)\n",
        "    hyperparameters = {\n",
        "        \"batch_size\": 1,\n",
        "        \"gamma\": 0.99,\n",
        "        \"epsilon_start\": 0.9,\n",
        "        \"epsilon_end\": 0.05,\n",
        "        \"tau\": 0.005,\n",
        "        \"epsilon_decay_steps\": 5000,\n",
        "        \"learning_rate\": 1e-4,\n",
        "        \"replay_buffer_size\": 10000,\n",
        "    }\n",
        "\n",
        "    # Initialize agent\n",
        "    agent = CNN_DQN_Agent(\n",
        "        input_shape=env.env.observation_space.shape,\n",
        "        DISCRETE_ACTIONS=env.DISCRETE_ACTIONS,\n",
        "        run_name=\"evaluation\",\n",
        "        img_stack=env_hyperparameters[\"img_stack\"],\n",
        "        **hyperparameters\n",
        "    )\n",
        "\n",
        "    # Load trained model weights\n",
        "    agent.load_checkpoint(checkpoint_file)\n",
        "\n",
        "    # Setup video writer\n",
        "    frame_size = (96, 96)  # Environment frame size\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    video_writer = cv2.VideoWriter(output_video, fourcc, 30, frame_size)\n",
        "    \n",
        "    # Run evaluation\n",
        "    for episode in range(episodes):\n",
        "        state, info = env.reset()\n",
        "        done = False\n",
        "        total_reward = 0\n",
        "\n",
        "        while not done:\n",
        "            # Select action using trained agent (disable exploration)\n",
        "            action = agent.select_action(state, explore=False)\n",
        "\n",
        "            # Step environment\n",
        "            state, reward, terminated, truncated, info = env.step(\n",
        "                agent.get_action_from_action_index(action.item()).cpu().numpy()\n",
        "            )\n",
        "            state = state.unsqueeze(0)\n",
        "\n",
        "            done = terminated or truncated\n",
        "            total_reward += reward\n",
        "\n",
        "            # **Fix: Extract only the last frame from stacked observation**\n",
        "            frame = state.squeeze().numpy()[-1]  # Select last frame (96, 96)\n",
        "\n",
        "            # Rescale pixel values to [0, 255]\n",
        "            frame = (frame * 255).astype(np.uint8)\n",
        "\n",
        "            # **Ensure frame is RGB (3 channels)**\n",
        "            if len(frame.shape) == 2:  # If grayscale (96, 96), convert to RGB\n",
        "                frame = np.stack([frame] * 3, axis=-1)  # Convert grayscale to RGB\n",
        "\n",
        "            # Debug print (optional)\n",
        "            #print(f\"Frame shape: {frame.shape}\")  # Should be (96, 96, 3)\n",
        "\n",
        "            # Write frame to video\n",
        "            video_writer.write(cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "            # Display in Colab (optional)\n",
        "            #cv2_imshow(frame)\n",
        "\n",
        "        print(f\"Episode {episode + 1}: Total Reward: {total_reward}\")\n",
        "\n",
        "    # Release video writer\n",
        "    video_writer.release()\n",
        "    print(f\"Video saved as {output_video}\")\n",
        "    files.download(output_video)\n",
        "\n",
        "    # Close environment\n",
        "    env.env.close()\n",
        "\n",
        "# Run the evaluation and record video\n",
        "evaluate_agent(checkpoint_file=\"CNN_DQN_20250212080216_episode_1000.pth\", episodes=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuqyKge61try"
      },
      "source": [
        "# Colored"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "3ZR6Z49L1s2b",
        "outputId": "5557f69d-25d3-4dc7-af2c-49eff2bad9c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checkpoint loaded from checkpoints/cnn_dqn/CNN_DQN_20250212080610_episode_500.pth on cpu\n",
            "Episode 1: Total Reward: -17.908108108108053\n",
            "Colored video saved as demo/CNN_DQN_20250212080610_episode_500_car_demo_colored.mp4\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_caa07b85-4780-4cf9-98f4-b31db5954874\", \"CNN_DQN_20250212080610_episode_500_car_demo_colored.mp4\", 93666)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch\n",
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "from agents.cnn_dqn import CNN_DQN_Agent\n",
        "from utils.env_wrapper import Env\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "# Function to run the trained agent and record a colored video\n",
        "def evaluate_agent(checkpoint_file, episodes=1):\n",
        "    filename = checkpoint_file[:-4]\n",
        "    output_video = f\"demo/{filename}_car_demo_colored.mp4\"\n",
        "\n",
        "    # Environment hyperparameters\n",
        "    env_hyperparameters = {\n",
        "        \"random_seed\": 3,\n",
        "        \"img_stack\": 4,  # Number of frames per state\n",
        "        \"action_repeat\": 8\n",
        "    }\n",
        "\n",
        "    # Initialize environment (Ensure RGB mode)\n",
        "    env = Env(\"CarRacing-v3\", **env_hyperparameters, render_mode=\"rgb_array\")\n",
        "\n",
        "    # Agent hyperparameters (same as training settings)\n",
        "    hyperparameters = {\n",
        "        \"batch_size\": 128,\n",
        "        \"gamma\": 0.99,\n",
        "        \"epsilon_start\": 0.9,\n",
        "        \"epsilon_end\": 0.05,\n",
        "        \"tau\": 0.005,\n",
        "        \"epsilon_decay_steps\": 5000,\n",
        "        \"learning_rate\": 1e-4,\n",
        "        \"replay_buffer_size\": 10000,\n",
        "    }\n",
        "\n",
        "    # Initialize agent\n",
        "    agent = CNN_DQN_Agent(\n",
        "        input_shape=env.env.observation_space.shape,\n",
        "        DISCRETE_ACTIONS=env.DISCRETE_ACTIONS,\n",
        "        run_name=\"evaluation\",\n",
        "        img_stack=env_hyperparameters[\"img_stack\"],\n",
        "        **hyperparameters\n",
        "    )\n",
        "\n",
        "    # Load trained model weights\n",
        "    agent.load_checkpoint(checkpoint_file)\n",
        "\n",
        "    # Setup video writer (Color output enabled)\n",
        "    frame_size = (96, 96)  # Environment frame size\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    video_writer = cv2.VideoWriter(output_video, fourcc, 30, frame_size)\n",
        "\n",
        "    # Run evaluation\n",
        "    for episode in range(episodes):\n",
        "        state, info = env.reset()\n",
        "        done = False\n",
        "        total_reward = 0\n",
        "\n",
        "        while not done:\n",
        "            # Select action using trained agent (disable exploration)\n",
        "            action = agent.select_action(state, explore=False)\n",
        "\n",
        "            # Step environment\n",
        "            state, reward, terminated, truncated, info = env.step(\n",
        "                agent.get_action_from_action_index(action.item()).cpu().numpy()\n",
        "            )\n",
        "            state = state.unsqueeze(0)\n",
        "\n",
        "            done = terminated or truncated\n",
        "            total_reward += reward\n",
        "\n",
        "            # **Fix: Extract only the last frame from stacked observation**\n",
        "            frame = state.squeeze().numpy()[-1]  # Select last frame (96, 96)\n",
        "\n",
        "            # Rescale pixel values to [0, 255]\n",
        "            frame = (frame * 255).astype(np.uint8)\n",
        "\n",
        "            # **Apply false color mapping (if grayscale)**\n",
        "            if len(frame.shape) == 2:  # If grayscale (96, 96)\n",
        "                frame = cv2.applyColorMap(frame, cv2.COLORMAP_DEEPGREEN)  # Convert grayscale to colored\n",
        "\n",
        "            # Debug print (optional)\n",
        "            #print(f\"Frame shape: {frame.shape}\")  # Should be (96, 96, 3)\n",
        "\n",
        "            # Write frame to video\n",
        "            video_writer.write(cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "        print(f\"Episode {episode + 1}: Total Reward: {total_reward}\")\n",
        "\n",
        "    # Release video writer\n",
        "    video_writer.release()\n",
        "    print(f\"Colored video saved as {output_video}\")\n",
        "    files.download(output_video)  # Download the colored video\n",
        "\n",
        "    # Close environment\n",
        "    env.env.close()\n",
        "\n",
        "# Run the evaluation and record video\n",
        "evaluate_agent(checkpoint_file=\"CNN_DQN_20250212080216_episode_1000.pth\", episodes=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "un1ZJ0Cs49VZ"
      },
      "source": [
        "# Just save when better as threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-1w6RIjb485V"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "from agents.cnn_dqn import CNN_DQN_Agent\n",
        "from utils.env_wrapper import Env\n",
        "\n",
        "# Function to run the trained agent and record a colored video only if reward ≥ 50\n",
        "def evaluate_agent(checkpoint_file, min_reward_threshold=50):\n",
        "    filename = checkpoint_file[:-4]  # Remove \".pth\" extension\n",
        "    output_video = f\"demo/{filename}_car_demo_colored.mp4\"\n",
        "\n",
        "    # Environment hyperparameters\n",
        "    env_hyperparameters = {\n",
        "        \"random_seed\": 3,\n",
        "        \"img_stack\": 4,  # Number of frames per state\n",
        "        \"action_repeat\": 8\n",
        "    }\n",
        "\n",
        "    # Initialize environment (Ensure RGB mode)\n",
        "    env = Env(\"CarRacing-v3\", **env_hyperparameters, render_mode=\"rgb_array\")\n",
        "\n",
        "    # Agent hyperparameters (same as training settings)\n",
        "    hyperparameters = {\n",
        "        \"batch_size\": 128,\n",
        "        \"gamma\": 0.99,\n",
        "        \"epsilon_start\": 0.9,\n",
        "        \"epsilon_end\": 0.05,\n",
        "        \"tau\": 0.005,\n",
        "        \"epsilon_decay_steps\": 5000,\n",
        "        \"learning_rate\": 1e-4,\n",
        "        \"replay_buffer_size\": 10000,\n",
        "    }\n",
        "\n",
        "    # Initialize agent\n",
        "    agent = CNN_DQN_Agent(\n",
        "        input_shape=env.env.observation_space.shape,\n",
        "        DISCRETE_ACTIONS=env.DISCRETE_ACTIONS,\n",
        "        run_name=\"evaluation\",\n",
        "        img_stack=env_hyperparameters[\"img_stack\"],\n",
        "        **hyperparameters\n",
        "    )\n",
        "\n",
        "    # Load trained model weights\n",
        "    agent.load_checkpoint(checkpoint_file)\n",
        "\n",
        "    # Retry until a successful episode (reward ≥ min_reward_threshold)\n",
        "    successful_episode = False\n",
        "    episode_count = 0\n",
        "\n",
        "    while not successful_episode:\n",
        "        episode_count += 1\n",
        "        print(f\"Starting Episode {episode_count}...\")\n",
        "\n",
        "        # Setup video writer (Temporary file, only saved if successful)\n",
        "        temp_video = f\"demo/{filename}_temp.mp4\"\n",
        "        frame_size = (96, 96)\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "        video_writer = cv2.VideoWriter(temp_video, fourcc, 30, frame_size)\n",
        "\n",
        "        state, info = env.reset()\n",
        "        done = False\n",
        "        total_reward = 0\n",
        "\n",
        "        while not done:\n",
        "            # Select action using trained agent (disable exploration)\n",
        "            action = agent.select_action(state, explore=False)\n",
        "\n",
        "            # Step environment\n",
        "            state, reward, terminated, truncated, info = env.step(\n",
        "                agent.get_action_from_action_index(action.item()).cpu().numpy()\n",
        "            )\n",
        "            state = state.unsqueeze(0)\n",
        "\n",
        "            done = terminated or truncated\n",
        "            total_reward += reward\n",
        "\n",
        "            # **Fix: Extract only the last frame from stacked observation**\n",
        "            frame = state.squeeze().numpy()[-1]  # Select last frame (96, 96)\n",
        "\n",
        "            # Rescale pixel values to [0, 255]\n",
        "            frame = (frame * 255).astype(np.uint8)\n",
        "\n",
        "            # **Apply false color mapping (if grayscale)**\n",
        "            if len(frame.shape) == 2:  # If grayscale (96, 96)\n",
        "                frame = cv2.applyColorMap(frame, cv2.COLORMAP_JET)  # Convert grayscale to colored\n",
        "\n",
        "            # Write frame to video\n",
        "            video_writer.write(cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "        # Release video writer\n",
        "        video_writer.release()\n",
        "\n",
        "        print(f\"Episode {episode_count}: Total Reward = {total_reward}\")\n",
        "\n",
        "        # Check if the episode meets the reward threshold\n",
        "        if total_reward >= min_reward_threshold:\n",
        "            successful_episode = True\n",
        "            os.rename(temp_video, output_video)  # Save the successful video\n",
        "            print(f\"✔ Success! Video saved as {output_video}\")\n",
        "        else:\n",
        "            print(f\"❌ Episode did not reach reward threshold. Retrying...\\n\")\n",
        "            os.remove(temp_video)  # Delete the unsuccessful video\n",
        "\n",
        "    # Close environment\n",
        "    env.env.close()\n",
        "\n",
        "# Run the evaluation and only save if reward ≥ 50\n",
        "evaluate_agent(checkpoint_file=\"CNN_DQN_20250212080216_episode_1000.pth\", min_reward_threshold=80)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
